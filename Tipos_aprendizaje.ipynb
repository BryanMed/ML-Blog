{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tipos_aprendizaje.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjZ4ehRiGIt5bwIoj7yyuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BryanMed/ML-Blog/blob/master/Tipos_aprendizaje.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_ij08xq8Ob1",
        "colab_type": "text"
      },
      "source": [
        "# Tipos de aprendizaje\n",
        "\n",
        "Según san wikipedia, el aprendizaje se define como:\n",
        "\n",
        "> \"Aprendizaje es el proceso de adquirir conocimiento (nuevo o modificando el existente) ... la habilidad de aprender está presente en humanos, animales y *algunas máquinas*\"\n",
        "\n",
        "De manera general podemos ver a este fenómeno como un proceso continuo que surge de las interacciones entre el agente y su ambiente. Desde el punto de vista del Machine Learning, podemos definir al aprendizaje mediante la siguiente secuencia de eventos:\n",
        "\n",
        "1.   El modelo es estimulado por el ambiente\n",
        "2.   El modelo es sometido a cambios en sus parámetros libres debido a este estimulo\n",
        "3.   Una vez este modelo sea estimulado nuevamente, este responderá de una manera distinta al ambiente, debido a los cambios que sufrió.\n",
        "\n",
        "Al hablar de modelos (matemáticos, no yo... bueno también aplica) podemos tomar como ejemplo al perceptrón, en donde el ambiente podemos verlo como el vector de entradas $x$, de acuerdo a su salida los parámetros libres (bias y pesos sinápticos) serán modificados, así, cuando la volvamos a someter el mismo ambiente/estímulo, la salida del perceptrón responderá de una manera distinta para bien o para mal.\n",
        "\n",
        "Existen diversas maneras por las que los modelos de Machine Learning pueden aprender, y estos métodos están clasificados de acuerdo a la manera en la que son modificados los parámetros libres, a continuación veremos algunos de ellos.\n",
        "\n",
        "## Aprendizaje por corrección del error\n",
        "Este tipo de aprendizaje toma al **error** como un mecanismo de control que permitirá ajustar los parámetros libres, recordando, el error $e(x)$ se calcula como la diferencia entre el valor esperado $y(x)$ y la predicción del modelo $\\hat{y}(x)$, es decir:\n",
        "\n",
        "$$ e(x) = y(x) - \\hat{y}(x)$$\n",
        "\n",
        "Lo que se espera que se logre con este tipo de aprendizaje es que el error vaya disminuyendo, indicando que la predicción sea cada vez menos diferente al valor esperado. \n",
        "\n",
        "Si bien esta manera de medir el error es muy intuitiva, no es recomendable ya que si queremos evaluar el *performance* final de nuestro modelo, tendremos que calcular y **sumar** el error de los elementos internos, por ejemplo, de cada perceptrón en una red neuronal. El utilizar este sencillo cálculo del error tiene dos principales problemirijillas:\n",
        "\n",
        "* No es una medida que esté normalizada, por lo que modelos que cuenten con más elementos o datos de entrada, tendrán más error que en los modelos simples. \n",
        "* Los errores de los elementos pueden ser positivos ($y = 1, \\hat{y} = 0 \\rightarrow e = 1 $) o negativos ($y = 0, \\hat{y} = 1 \\rightarrow e = -1$), lo que al sumar todos los errores, se puede dar el caso de que muchos de estos se cancelen entre ellos. \n",
        "\n",
        "Para evitar estos inconvenientes, son utilizadas las **funciones de costo** que permiten cuantificar la capacidad de realizar buenas o malas predicciones al modelo de machine learning. Entre las más populares encontramos:\n",
        "\n",
        "### Error absoluto medio (_mean absolute error_)\n",
        "\n",
        "El error absoluto medio se calcula por medio de la siguiente expresión:\n",
        "\n",
        "$$ MAE = \\frac{1}{m} \\sum_{i=1}^{m}|\\hat{y}_i - y_i| $$\n",
        "$$ = \\frac{1}{m} \\sum_{i=1}^{m}|e_i|$$\n",
        "\n",
        "Este índice genera el promedio de los errores absolutos ($|e_i| = \\hat{y}_i - y_i$)\n",
        "\n",
        "### Error cuadrático medio (_mean squared error_)\n",
        "\n",
        "El error cuadrático medio se caclula a partir de:\n",
        "\n",
        "$$ MSE = \\frac{1}{m} \\sum_{i=1}^{m}(\\hat{y}_i - y_i)^2 $$\n",
        "$$ = \\frac{1}{m} \\sum_{i=1}^{m}e_i^2$$\n",
        "Y esta vez lo que se calcula es el promedio de los errores al cuadrado\n",
        "\n",
        "Estas son solo algunas de las funciones de costo más populares, donde cada una tiene sus ventajas y desventajas, en la documentación de [tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/losses) podrás observar más de estas funciones.\n",
        "\n",
        "---\n",
        "\n",
        "Ahora que platicamos de algunas maneras del calcular el error, podemos discutir algunos de los métodos de aprendizaje.\n",
        "\n",
        "### Aprendizaje basado en memoria \n",
        "\n",
        "En los aprendizajes basados en memoria, se almacenan explícitamente ejemplos de clasificaciones correctas entrada-salida.\n",
        "\n",
        "La idea principal de este enfoque es que permite a los modelos clasificar conceptos por su similaridad con conceptos anteriormente mostrados. La fortaleza de este sistema es la capacidad de calcular la similaridad entre los nuevos datos respecto a los datos utilizados en el entrenamiento.\n",
        "\n",
        "Un algoritmo representativo de este tipo de aprendizaje es el **K vecinos más cercanos**, en el que se utilizan vectores de entrenamiento que son particionados en regiones basadas en etiquetas. En la fase de entrenamiento del algoritmo, se almacenan los vectores característicos y las etiquetas de las clases de los ejemplos de entrenamiento, mientras que en la fase de clasificaciónn, se evalúan los ejemplos, se calcula la distancia entre el valores almacenados y el nuevo vector y se seleccionan los $k$ ejemplos más cercanos.\n",
        "\n",
        "### Aprendizaje Hebbiano\n",
        "Se basa en ela teoría hebbiana el cual se refiere a la plasticidad sináptica en el que el valor de una conexión sináptica se incrementa si las neuronas de ambos lados de dichas sinapsis se activan repetidas veces de forma simultanea, en pocas palabras\"las células que se disparan juntas, permanecerán conectadas\". Desde el punto de vista de neuronas artificiales, este principio se describe como in método para determinar la forma en la que se modifican los pesos entre las neuronas. El peso entre dos neuronas se incremwnta si las dos neuronas se activa simultaneamente y se reduce si se activan por separado. La formulación de este aprendizaje es como sigue:\n",
        "\n",
        "$$w_{ij} = x_ix_j$$\n",
        "\n",
        "En donde $w_{ij}$ es el peso de la conexión de la neurona $j$ a la neurona $i$ y $x_i$ el valor de entrada para la neurona $i$\n",
        "\n",
        "### Aprendizaje competitivo\n",
        "Los modelos de aprendizaje competitivo se diferencian de los otros modelos en la manera que se representan los patrones. En los modelos tradicionales, las neuronas colaboran para presentar generar un patrón, sin embargo, en este tipo de redes cada neurona compite con las otras neuronas para representar los patrones.\n",
        "Las neuronas compiten en cual representa mejor al patrón y la ganadora se lleva todo el aprendizaje de ese patrón. \n",
        "\n",
        "El aprendizaje de esta red se basa en comparar los patrones con los pesos sinápticos que llegan a las neuronas de salida. La función actualizar de la neurona asigna valores mayores a las neuronas de salida que representan mejor el patrón. Una vez que sabemos cual es la neurona ganadora, hacemos que sus pesos acerquen aún más a los patrones para que la aprendan.\n",
        "\n",
        "El problema de esta red son las neuronas muertas, son neuronas de la capa de salida que no han ganado nunca y no representan ningun grupo de aptrones y por tanto no sirven para nada.\n",
        "\n",
        "\n",
        "### Aprendizaje de Boltzmann\n",
        "Derivado del campo de la termodinámica, es muy similar al aprendizaje por correccción del error y es utilizado durante el aprendizaje supervizado. En este algoritmo el estado de cada neurona individual, además de la salida del sistema son tomados en consideración. En las máquinas de Boltzmann las neuronas constituyen una estructura recurrente y trabajan de manera binaria (estados \"on\" y \"off\"). Esta máquina es caracterizada por una función de energia E, cuyo valor es determinado por los estados particulaes ocupados por las neuronas individules de la máquina.\n",
        "\n",
        "Las neuronas de una máquina de Boltzmann se clasifican en dos grupos, _visibles_ y _invisibles_.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBi4FTGE8B2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}